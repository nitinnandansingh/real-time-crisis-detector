{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e56fd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/transformers/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "print(transformers.__file__)\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34df38d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.7.0\n",
      "Transformers Version: 4.31.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ff5a7a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf79af28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13999, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non_real_time_crisis</td>\n",
       "      <td>#earthquake Magnitude 2.1 occurred 159km NE of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non_real_time_crisis</td>\n",
       "      <td>Retweeted Earthquakes Tsunamis (@NewEarthquake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non_real_time_crisis</td>\n",
       "      <td>I always know I need to go shopping when I've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non_real_time_crisis</td>\n",
       "      <td>Update: M2.0 #earthquake (#sismo) strikes 1 km...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non_real_time_crisis</td>\n",
       "      <td>ã€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  label                                               text\n",
       "0  non_real_time_crisis  #earthquake Magnitude 2.1 occurred 159km NE of...\n",
       "1  non_real_time_crisis  Retweeted Earthquakes Tsunamis (@NewEarthquake...\n",
       "2  non_real_time_crisis  I always know I need to go shopping when I've ...\n",
       "3  non_real_time_crisis  Update: M2.0 #earthquake (#sismo) strikes 1 km...\n",
       "4  non_real_time_crisis                                                 ã€"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/disaster_df.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be5c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'non_real_time_crisis': 0, 'real_time_crisis': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a631e117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#earthquake Magnitude 2.1 occurred 159km NE of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Retweeted Earthquakes Tsunamis (@NewEarthquake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I always know I need to go shopping when I've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Update: M2.0 #earthquake (#sismo) strikes 1 km...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ã€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  #earthquake Magnitude 2.1 occurred 159km NE of...\n",
       "1      0  Retweeted Earthquakes Tsunamis (@NewEarthquake...\n",
       "2      0  I always know I need to go shopping when I've ...\n",
       "3      0  Update: M2.0 #earthquake (#sismo) strikes 1 km...\n",
       "4      0                                                 ã€"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920f34f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 11199, Validation size: 2800\n"
     ]
    }
   ],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'].tolist(), df['label'].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Train size: {len(train_texts)}, Validation size: {len(val_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f513921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Tokenize the text (padding and truncating it to max_length)\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # The tokenizer returns a dictionary of tensors, so we need to extract them\n",
    "        input_ids = encoding['input_ids'].flatten()\n",
    "        attention_mask = encoding['attention_mask'].flatten()\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a2c0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 4. Create Dataset Instances\n",
    "train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = CustomDataset(val_texts, val_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8d92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create DataLoader for batching\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc655de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 6. Load Pre-trained BERT Model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc155f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='../results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2edfea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Initialize Trainer with Custom Dataset\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=None,\n",
    "    compute_metrics=lambda p: classification_report(p.predictions.argmax(axis=1), p.label_ids, output_dict=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd91278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/4200 [00:00<?, ?it/s]/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 12%|█▏        | 500/4200 [1:45:47<3:15:25,  3.17s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4081, 'learning_rate': 5e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1000/4200 [2:12:55<3:03:39,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3503, 'learning_rate': 4.324324324324325e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1400/4200 [2:37:40<2:50:53,  3.66s/it]/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                       \n",
      " 33%|███▎      | 1400/4200 [2:44:26<2:50:53,  3.66s/it]/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2962515652179718, 'eval_0': {'precision': 0.9638495359062041, 'recall': 0.9005020538566865, 'f1-score': 0.9310995752713545, 'support': 2191.0}, 'eval_1': {'precision': 0.7104913678618858, 'recall': 0.8784893267651889, 'f1-score': 0.7856093979441997, 'support': 609.0}, 'eval_accuracy': 0.8957142857142857, 'eval_macro avg': {'precision': 0.837170451884045, 'recall': 0.8894956903109377, 'f1-score': 0.858354486607777, 'support': 2800.0}, 'eval_weighted avg': {'precision': 0.908744134356565, 'recall': 0.8957142857142857, 'f1-score': 0.8994554617026984, 'support': 2800.0}, 'eval_runtime': 406.3325, 'eval_samples_per_second': 6.891, 'eval_steps_per_second': 0.861, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1500/4200 [2:50:07<2:17:24,  3.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2995, 'learning_rate': 3.648648648648649e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2000/4200 [4:07:57<45:59:16, 75.25s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2304, 'learning_rate': 2.9729729729729733e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 2500/4200 [4:45:26<1:33:05,  3.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.224, 'learning_rate': 2.2972972972972976e-05, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2800/4200 [5:02:00<1:18:21,  3.36s/it]/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                       \n",
      " 67%|██████▋   | 2800/4200 [5:07:56<1:18:21,  3.36s/it]/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3611055016517639, 'eval_0': {'precision': 0.9579872984855886, 'recall': 0.9241281809613572, 'f1-score': 0.9407531782201967, 'support': 2122.0}, 'eval_1': {'precision': 0.7861885790172642, 'recall': 0.8731563421828908, 'f1-score': 0.827393431167016, 'support': 678.0}, 'eval_accuracy': 0.9117857142857143, 'eval_macro avg': {'precision': 0.8720879387514264, 'recall': 0.898642261572124, 'f1-score': 0.8840733046936063, 'support': 2800.0}, 'eval_weighted avg': {'precision': 0.9163874657000444, 'recall': 0.9117857142857143, 'f1-score': 0.9133039251837479, 'support': 2800.0}, 'eval_runtime': 356.1955, 'eval_samples_per_second': 7.861, 'eval_steps_per_second': 0.983, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 3000/4200 [5:18:11<58:47,  2.94s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.152, 'learning_rate': 1.6216216216216218e-05, 'epoch': 2.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 3500/4200 [6:27:04<31:44,  2.72s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1117, 'learning_rate': 9.45945945945946e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 4000/4200 [6:54:40<11:25,  3.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1069, 'learning_rate': 2.702702702702703e-06, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4200/4200 [7:06:27<00:00,  3.56s/it]/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                     \n",
      "100%|██████████| 4200/4200 [7:13:13<00:00,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42944231629371643, 'eval_0': {'precision': 0.9399120664386907, 'recall': 0.9376218323586745, 'f1-score': 0.9387655525737985, 'support': 2052.0}, 'eval_1': {'precision': 0.8300132802124834, 'recall': 0.8355614973262032, 'f1-score': 0.832778147901399, 'support': 748.0}, 'eval_accuracy': 0.9103571428571429, 'eval_macro avg': {'precision': 0.8849626733255871, 'recall': 0.8865916648424388, 'f1-score': 0.8857718502375987, 'support': 2800.0}, 'eval_weighted avg': {'precision': 0.9105533906896897, 'recall': 0.9103571428571429, 'f1-score': 0.9104517744684574, 'support': 2800.0}, 'eval_runtime': 405.7734, 'eval_samples_per_second': 6.9, 'eval_steps_per_second': 0.863, 'epoch': 3.0}\n",
      "{'train_runtime': 25993.2571, 'train_samples_per_second': 1.293, 'train_steps_per_second': 0.162, 'train_loss': 0.22783626261211576, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4200, training_loss=0.22783626261211576, metrics={'train_runtime': 25993.2571, 'train_samples_per_second': 1.293, 'train_steps_per_second': 0.162, 'train_loss': 0.22783626261211576, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dcb8c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|██████████| 350/350 [06:48<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42944231629371643, 'eval_0': {'precision': 0.9399120664386907, 'recall': 0.9376218323586745, 'f1-score': 0.9387655525737985, 'support': 2052.0}, 'eval_1': {'precision': 0.8300132802124834, 'recall': 0.8355614973262032, 'f1-score': 0.832778147901399, 'support': 748.0}, 'eval_accuracy': 0.9103571428571429, 'eval_macro avg': {'precision': 0.8849626733255871, 'recall': 0.8865916648424388, 'f1-score': 0.8857718502375987, 'support': 2800.0}, 'eval_weighted avg': {'precision': 0.9105533906896897, 'recall': 0.9103571428571429, 'f1-score': 0.9104517744684574, 'support': 2800.0}, 'eval_runtime': 409.2196, 'eval_samples_per_second': 6.842, 'eval_steps_per_second': 0.855, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Evaluate the Model\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79bcf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_texts(texts, model, tokenizer, max_length=512):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "\n",
    "    for text in texts:\n",
    "        # Tokenize the text\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Move to GPU if available\n",
    "        input_ids = encoding['input_ids'].to(model.device)\n",
    "        attention_mask = encoding['attention_mask'].to(model.device)\n",
    "\n",
    "        # Perform prediction without calculating gradients\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predicted_class = torch.argmax(logits, dim=1).item()\n",
    "            predictions.append(predicted_class)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbbdeed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: A massive earthquake has hit the city, buildings are collapsing!\n",
      "Prediction: real_time_crisis\n",
      "\n",
      "Text: The weather is nice today, perfect for a picnic.\n",
      "Prediction: real_time_crisis\n",
      "\n",
      "Text: Emergency services are responding to the flood in the area.\n",
      "Prediction: real_time_crisis\n",
      "\n",
      "Text: The local sports team won the championship game last night.\n",
      "Prediction: non_real_time_crisis\n",
      "\n",
      "Text: A new restaurant has opened downtown, serving delicious food.\n",
      "Prediction: non_real_time_crisis\n",
      "\n",
      "Text: There are reports of a wildfire spreading in the forest.\n",
      "Prediction: non_real_time_crisis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample texts for prediction\n",
    "sample_texts = [\n",
    "    \"A massive earthquake has hit the city, buildings are collapsing!\",\n",
    "    \"The weather is nice today, perfect for a picnic.\",\n",
    "    \"Emergency services are responding to the flood in the area.\",\n",
    "    \"The local sports team won the championship game last night.\",\n",
    "    \"A new restaurant has opened downtown, serving delicious food.\",\n",
    "    \"There are reports of a wildfire spreading in the forest.\",\n",
    "]\n",
    "\n",
    "# Use the prediction function\n",
    "predictions = predict_texts(sample_texts, model, tokenizer)\n",
    "label_map = {0: \"non_real_time_crisis\", 1: \"real_time_crisis\"}\n",
    "\n",
    "for text, pred in zip(sample_texts, predictions):\n",
    "    print(f\"Text: {text}\\nPrediction: {label_map[pred]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c037c6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_model/tokenizer_config.json',\n",
       " './saved_model/special_tokens_map.json',\n",
       " './saved_model/vocab.txt',\n",
       " './saved_model/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('../saved_model')\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('../saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d2e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
